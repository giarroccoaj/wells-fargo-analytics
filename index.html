<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Wells Fargo Analytics Competition by giarroccoaj</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Wells Fargo Analytics Competition</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/giarroccoaj/wells-fargo-analytics" class="btn">View on GitHub</a>
      <a href="https://github.com/giarroccoaj/wells-fargo-analytics/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/giarroccoaj/wells-fargo-analytics/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction.</h1>

<p>Throughout my Data 101 course I was introduced to the concepts and theories behind Data Science that make it such an interdisciplinary field. Using the R programming language and popular algorithms in Big Data I was able to explore real world data and gain practical experience as a Data Scientist. </p>

<p>A recurring theme, or observation, when looking into Big Data is the idea that large data sets are difficult to make sense of (i.e: unstructured). The challenge is often to make sense of (structure) this data. </p>

<p>Wells Fargo opened a competition that I participated in for my final project in my Data 101 course. </p>

<h1>
<a id="the-competition" class="anchor" href="#the-competition" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Competition.</h1>

<p>“Dialogues on social media can provide tremendous insight into the behaviors, desires, pains, and thoughts of consumers. We'd like your help in developing a repeatable process that identifies, classifies, and extracts the underlying drivers of consumer financial conversations and comments in social media data.”</p>

<p>Using just <a href="https://d18qs7yq39787j.cloudfront.net/uploads/contestfile/93/8af8575b213c-2015%2BWells%2BFargo%2BCampus%2BAnalytic%2BChallenge%2BDataset.txt">this document</a>, a team of 3 others and myself were tasked with answering two questions: </p>

<p>*<em>Question #1: What financial topics do consumers discuss on social media and what caused the consumers to post about this topic? *</em></p>

<p>*<em>Question #2: Are the topics and “substance” consistent across the industry or are they isolated to individual banks? *</em></p>

<p>With these two questions in mind, we had our work cut out for us.</p>

<h1>
<a id="the-solution" class="anchor" href="#the-solution" aria-hidden="true"><span class="octicon octicon-link"></span></a>The Solution</h1>

<p>Using the dataset, the first challenge – like in much of big data – was to structure or clean its contents. Un-cleaned, the social media posts looked like this:</p>

<p><img src="http://i.imgur.com/8hdjJ2H.png" alt='Note the recurrent terms, i.e: "INTERNET", "twit_handl"... We need to take these out!'></p>

<p>With over 200,000 posts in the entire data set, our team chose make a smaller data frame of 10,000 random samples - what we believed to be a large enough sample size. </p>

<div class="highlight highlight-source-r"><pre><span class="pl-v">df</span> <span class="pl-k">=</span> read.table(<span class="pl-s"><span class="pl-pds">'</span>dataset.txt<span class="pl-pds">'</span></span>,<span class="pl-v">sep</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>|<span class="pl-pds">"</span></span>,<span class="pl-v">header</span><span class="pl-k">=</span><span class="pl-c1">T</span>) <span class="pl-c">#convert .txt document to data frame</span>
<span class="pl-v">idx.10000</span> <span class="pl-k">=</span> sample(<span class="pl-c1">1</span><span class="pl-k">:</span>nrow(<span class="pl-smi">df</span>),<span class="pl-c1">10000</span>) <span class="pl-c">#find 10,000 random numbers</span>
<span class="pl-v">df.10000</span> <span class="pl-k">=</span> <span class="pl-smi">df</span>[<span class="pl-smi">idx.10000</span>,] <span class="pl-c">#create new data frame of 10,000 posts using random indices</span></pre></div>

<p>In an effort to clean the data frame, it must be made suitable for the text mining package and therefore it must be a Corpus(collection of text documents). Here is the code to convert Data Frame to Corpus and code to clean Corpus of unnecessary meta data.</p>

<div class="highlight highlight-source-r"><pre>library(<span class="pl-smi">tm</span>) 
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> Corpus(DataframeSource(as.data.frame(<span class="pl-smi">df.10000</span>[,<span class="pl-c1">6</span>]))) 
library(<span class="pl-smi">rJava</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, content_transformer(<span class="pl-smi">tolower</span>)) <span class="pl-c"># convert to lowercase first</span>
<span class="pl-c">#metaData/recurrent words</span>
<span class="pl-smi">myMeta</span> <span class="pl-k">&lt;-</span> c(<span class="pl-s"><span class="pl-pds">"</span>name<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>bank<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>banka<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>bankb<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>bankc<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>bankd<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>banke<span class="pl-pds">"</span></span>,
            <span class="pl-s"><span class="pl-pds">"</span>internet<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>https<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>twit_hndl<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>twit_hndl_banka<span class="pl-pds">"</span></span>,
            <span class="pl-s"><span class="pl-pds">"</span>twit_hndl_bankb<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>twit_hndl_bankc<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>twit_hndl_bankd<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>phone<span class="pl-pds">"</span></span>,
            <span class="pl-s"><span class="pl-pds">"</span>dirmsg<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>street<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>name_resp<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>bankds<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>and<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>for<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>the<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>you<span class="pl-pds">"</span></span>,
            <span class="pl-s"><span class="pl-pds">"</span>twithndlbanka<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>dirmsg<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>ret_twit<span class="pl-pds">"</span></span>)
<span class="pl-c">#REMEMBER: IT MATTERS THE ORDER IN WHICH TM_MAP EXPRESSIONS ARE RUN</span>
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, <span class="pl-smi">myMeta</span>) <span class="pl-c">#remove words found in myMeta vector</span>
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, stopwords(<span class="pl-s"><span class="pl-pds">'</span>english<span class="pl-pds">'</span></span>)) <span class="pl-c">#remove english stopwords</span>
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removeWords</span>, stopwords(<span class="pl-v">kind</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>SMART<span class="pl-pds">"</span></span>)) <span class="pl-c">#remove even more stopwords</span>
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">stripWhitespace</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">removePunctuation</span>)
<span class="pl-smi">docs</span> <span class="pl-k">&lt;-</span> tm_map(<span class="pl-smi">docs</span>, <span class="pl-smi">PlainTextDocument</span>)</pre></div>

<p>Following this code, the posts now look like the following</p>

<p><img src="http://i.imgur.com/dWYC0Wo.png" alt=""></p>

<p>Now that the data has been cleaned, analysis can be done.</p>

<p>To find out what topics consumers talked about on social media, we went ahead ran sentiment analysis on the newly cleaned data. Using the 10,000 social media posts, we compared them to lists of positive and negative words.</p>

<p>But to do this, the Corpus must first be turned into a Document-Term Matrix, removed of sparse terms, and turned back into a data frame</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">dtm</span> <span class="pl-k">&lt;-</span> DocumentTermMatrix(<span class="pl-smi">docs</span>)
<span class="pl-v">dtm</span> <span class="pl-k">=</span> removeSparseTerms(<span class="pl-smi">dtm</span>, <span class="pl-c1">0.98</span>) <span class="pl-c">#removes words with very low frequency</span>
<span class="pl-smi">new.df</span> <span class="pl-k">&lt;-</span> <span class="pl-k">data.frame</span>(<span class="pl-v">text</span><span class="pl-k">=</span>unlist(sapply(<span class="pl-smi">docs</span>, `[[`, <span class="pl-s"><span class="pl-pds">"</span>content<span class="pl-pds">"</span></span>)), <span class="pl-v">stringsAsFactors</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)</pre></div>

<p>With new.df, we come up with sentiment scores that can be used to make wordclouds and other plots using the following function</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">pos</span> <span class="pl-k">&lt;-</span> scan(<span class="pl-s"><span class="pl-pds">'</span>positive-words.txt<span class="pl-pds">'</span></span>,<span class="pl-v">what</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>character<span class="pl-pds">'</span></span>,<span class="pl-v">comment.char</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>;<span class="pl-pds">'</span></span>)
<span class="pl-smi">neg</span> <span class="pl-k">&lt;-</span> scan(<span class="pl-s"><span class="pl-pds">'</span>negative-words.txt<span class="pl-pds">'</span></span>,<span class="pl-v">what</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>character<span class="pl-pds">'</span></span>,<span class="pl-v">comment.char</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>;<span class="pl-pds">'</span></span>)

<span class="pl-v">score.sentiment</span> <span class="pl-k">=</span> <span class="pl-k">function</span>(<span class="pl-smi">sentences</span>, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>none<span class="pl-pds">'</span></span>)
{
  require(<span class="pl-smi">plyr</span>)
  require(<span class="pl-smi">stringr</span>)

  <span class="pl-c"># we got a vector of sentences. plyr will handle a list</span>
  <span class="pl-c"># or a vector as an "l" for us</span>
  <span class="pl-c"># we want a simple array ("a") of scores back, so we use </span>
  <span class="pl-c"># "l" + "a" + "ply" = "laply":</span>
  <span class="pl-v">scores</span> <span class="pl-k">=</span> laply(<span class="pl-smi">sentences</span>, <span class="pl-k">function</span>(<span class="pl-smi">sentence</span>, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>) {

    <span class="pl-c"># clean up sentences with R's regex-driven global substitute, gsub():</span>
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span>[[:punct:]]<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span>[[:cntrl:]]<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> gsub(<span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\\</span>d+<span class="pl-pds">'</span></span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-pds">'</span></span>, <span class="pl-smi">sentence</span>)
    <span class="pl-c"># and convert to lower case:</span>
    <span class="pl-v">sentence</span> <span class="pl-k">=</span> tolower(<span class="pl-smi">sentence</span>)

    <span class="pl-c"># split into words. str_split is in the stringr package</span>
    <span class="pl-v">word.list</span> <span class="pl-k">=</span> str_split(<span class="pl-smi">sentence</span>, <span class="pl-s"><span class="pl-pds">'</span><span class="pl-cce">\\</span>s+<span class="pl-pds">'</span></span>)
    <span class="pl-c"># sometimes a list() is one level of hierarchy too much</span>
    <span class="pl-v">words</span> <span class="pl-k">=</span> unlist(<span class="pl-smi">word.list</span>)

    <span class="pl-c"># compare our words to the dictionaries of positive &amp; negative terms</span>
    <span class="pl-v">pos.matches</span> <span class="pl-k">=</span> match(<span class="pl-smi">words</span>, <span class="pl-smi">pos.words</span>)
    <span class="pl-v">neg.matches</span> <span class="pl-k">=</span> match(<span class="pl-smi">words</span>, <span class="pl-smi">neg.words</span>)

    <span class="pl-c"># match() returns the position of the matched term or NA</span>
    <span class="pl-c"># we just want a TRUE/FALSE:</span>
    <span class="pl-v">pos.matches</span> <span class="pl-k">=</span> <span class="pl-k">!</span>is.na(<span class="pl-smi">pos.matches</span>)
    <span class="pl-v">neg.matches</span> <span class="pl-k">=</span> <span class="pl-k">!</span>is.na(<span class="pl-smi">neg.matches</span>)

    <span class="pl-c"># and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():</span>
    <span class="pl-v">score</span> <span class="pl-k">=</span> sum(<span class="pl-smi">pos.matches</span>) <span class="pl-k">-</span> sum(<span class="pl-smi">neg.matches</span>)

    <span class="pl-k">return</span>(<span class="pl-smi">score</span>)
  }, <span class="pl-smi">pos.words</span>, <span class="pl-smi">neg.words</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span>.<span class="pl-smi">progress</span> )

  <span class="pl-v">scores.df</span> <span class="pl-k">=</span> <span class="pl-k">data.frame</span>(<span class="pl-v">score</span><span class="pl-k">=</span><span class="pl-smi">scores</span>, <span class="pl-v">text</span><span class="pl-k">=</span><span class="pl-smi">sentences</span>)
  <span class="pl-k">return</span>(<span class="pl-smi">scores.df</span>)
}

<span class="pl-v">scores</span> <span class="pl-k">=</span> score.sentiment(<span class="pl-smi">new.df</span><span class="pl-k">$</span><span class="pl-smi">FullText</span>, <span class="pl-smi">pos</span>, <span class="pl-smi">neg</span>, <span class="pl-v">.progress</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>text<span class="pl-pds">'</span></span>)</pre></div>

<p>Using the value scores we come up with the following positive and negative wordclouds...</p>

<p><img src="http://i.imgur.com/hBcgAz8.png" alt="Positive Sentiment"></p>

<p><img src="http://i.imgur.com/ToEVUrM.png" alt="Negative Sentiment"></p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/giarroccoaj/wells-fargo-analytics">Wells Fargo Analytics Competition</a> is maintained by <a href="https://github.com/giarroccoaj">giarroccoaj</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
